<!doctype html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><meta name="google-adsense-account" content="ca-pub-8982726393306273"><title id="page-title">Gemma - 谷歌推出的新一代轻量级开放模型 AI 工具详情</title><meta name="description" content="Gemma是由谷歌DeepMind和谷歌的其他团队开发的一系列轻量级、先进的开放AI模型，基于与Gemini模型相同的技术，旨在帮助开发者和研究人员构建负责任的AI应用。Gemma模型系列包括两种权重规模的模型：Gemma 2B 和 Gemma 7B，提供预训练和指令微调版本，支持多种框架，如JAX、PyTorch和TensorFlow，以在不同设备上高效运行。"><link rel="canonical" href="https://aistool.org/gemma.html"><meta property="og:title" content="Gemma |  AI 工具详情"><meta property="og:description" content="Gemma是由谷歌DeepMind和谷歌的其他团队开发的一系列轻量级、先进的开放AI模型，基于与Gemini模型相同的技术，旨在帮助开发者和研究人员构建负责任的AI应用。Gemma模型系列包括两种权重规模的模型：Gemma 2B 和 Gemma 7B，提供预训练和指令微调版本，支持多种框架，如JAX、PyTorch和TensorFlow，以在不同设备上高效运行。 "><meta property="og:type" content="website"><meta property="og:url" content="https://aistool.org/gemma.html"><meta property="og:image" content="https://aistool.org/img/gemma.png"><script async src="https://www.googletagmanager.com/gtag/js?id=G-3CPK6GJ06E"></script><script>if(["aistool.org"].includes(window.location.hostname)){function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-3CPK6GJ06E")}else console.log(`[GA4 DEV MODE] GA tracking is disabled on: ${window.location.hostname}`)</script><link rel="stylesheet" href="./style/detail.css?v=9"><script type="application/ld+json">{
            "@context": "https://schema.org",
            "@type": "SoftwareApplication",
            "name": "Gemma",
            "description": "谷歌推出的新一代轻量级开放模型",
            "url": "https://aistool.org/gemma.html",
            "image": "https://aistool.org/img/gemma.png",
            "applicationCategory": "http://schema.org/SoftwareApplication",
            "keywords": "AI训练模型",
            "author": {
              "@type": "Person",
              "name": "ai工具导航"
            }
        }</script></head><body><div id="app"><header class="header"><a href="index.html" class="back-btn">← 返回首页</a><h1>工具详情</h1><div style="width:80px"></div></header><main class="content"><div id="detail-view"><div class="detail-page"><div class="detail-header"><img src="./img/gemma.png" class="detail-icon-img" alt="Gemma logo"><h2 class="detail-title">Gemma</h2><span class="tag-pill">AI训练模型</span></div><a href="https://www.bing.com/search?q=Gemma" target="_blank" class="cta-btn">🚀 立即前往</a><article class="detail-body"><p>Gemma是什么 Gemma是由谷歌DeepMind和谷歌的其他团队开发的一系列轻量级、先进的开放AI模型，基于与Gemini模型相同的技术，旨在帮助开发者和研究人员构建负责任的AI应用。Gemma模型系列包括两种权重规模的模型：Gemma 2B 和 Gemma 7B，提供预训练和指令微调版本，支持多种框架，如JAX、PyTorch和TensorFlow，以在不同设备上高效运行。6月28日，第二代模型Gemma 2已发布。 Gemma的官方入口 Gemma的官网主页：https://ai.google.dev/gemma?hl=zh-cn Gemma的Hugging Face模型：https://huggingface.co/models?search=google/gemma Gemma的Kaggle模型地址：https://www.kaggle.com/models/google/gemma/code/ Gemma的技术报告：https://storage.googleapis.com/deepmind-media/gemma/gemma-report.pdf 官方PyTorch实现GitHub代码库：https://github.com/google/gemma_pytorch Gemma的Google Colab运行地址：https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/gemma/docs/lora_tuning.ipynb Gemma的主要特性 轻量级架构：Gemma模型设计为轻量级，便于在多种计算环境中运行，包括个人电脑和工作站。 开放模型：Gemma模型的权重是开放的，允许用户在遵守许可协议的情况下进行商业使用和分发。 预训练与指令微调：提供预训练模型和经过指令微调的版本，后者通过人类反馈强化学习（RLHF）来确保模型行为的负责任性。 多框架支持：Gemma支持JAX、PyTorch和TensorFlow等主要AI框架，通过Keras 3.0提供工具链，简化了推理和监督微调（SFT）过程。 安全性与可靠性：在设计时，Gemma遵循Google的AI原则，使用自动化技术过滤训练数据中的敏感信息，并进行了一系列安全评估，包括红队测试和对抗性测试。 性能优化：Gemma模型针对NVIDIA GPU和Google Cloud TPUs等硬件平台进行了优化，确保在不同设备上都能实现高性能。 社区支持：Google提供了Kaggle、Colab等平台的免费资源，以及Google Cloud的积分，鼓励开发者和研究人员利用Gemma进行创新和研究。 跨平台兼容性：Gemma模型可以在多种设备上运行，包括笔记本电脑、台式机、物联网设备和云端，支持广泛的AI功能。 负责任的AI工具包：Google还发布了Responsible Generative AI Toolkit，帮助开发者构建安全和负责任的AI应用，包括安全分类器、调试工具和应用指南。 Gemma的技术要点 模型架构：Gemma基于Transformer解码器构建，这是当前自然语言处理（NLP）领域最先进的模型架构之一。采用了多头注意力机制，允许模型在处理文本时同时关注多个部分。此外，Gemma还使用了旋转位置嵌入（RoPE）来代替绝对位置嵌入，以减少模型大小并提高效率。GeGLU激活函数取代了标准的ReLU非线性激活，以及在每个Transformer子层的输入和输出都进行了归一化处理。 训练基础设施：Gemma模型在Google的TPUv5e上进行训练，这是一种专为机器学习设计的高性能计算平台。通过在多个Pod（芯片集群）上进行模型分片和数据复制，Gemma能够高效地利用分布式计算资源。 预训练数据：Gemma模型在大量英语数据上进行预训练（2B模型大约2万亿个token的数据上预训练，而7B模型则基于6万亿个token），这些数据主要来自网络文档、数学和代码。预训练数据经过过滤，以减少不想要或不安全的内容，同时确保数据的多样性和质量。 微调策略：Gemma模型通过监督式微调（SFT）和基于人类反馈的强化学习（RLHF）进行微调。这包括使用合成的文本对和人类生成的提示响应对，以及基于人类偏好数据训练的奖励模型。 安全性和责任：Gemma在设计时考虑了模型的安全性和责任，包括在预训练阶段对数据进行过滤，以减少敏感信息和有害内容的风险。此外，Gemma还通过了一系列的安全性评估，包括自动化基准测试和人类评估，以确保模型在实际应用中的安全性。 性能评估：Gemma在多个领域进行了广泛的性能评估，包括问答、常识推理、数学和科学问题解答以及编码任务。Gemma模型与同样规模或更大规模的开放模型进行了性能对比，在MMLU、MBPP等18个基准测试中，有11个测试结果超越了Llama-13B或Mistral-7B等模型。 开放性和可访问性：Gemma模型以开源的形式发布，提供了预训练和微调后的检查点，以及推理和部署的开源代码库。这使得研究人员和开发者能够访问和利用这些先进的语言模型，推动AI领域的创新。 常见问题 Gemma一词的含义是什么？ Gemma在拉丁语中的意思是“宝石”。 Gemma是开源的吗？ Gemma是开源开放的大模型，用户可在Hugging Face查看和下载其模型。 Gemma模型的参数量是多少？ Gemma目前提供20亿和70亿参数量的模型，后续还会推出新的变体。</p></article></div></div></main></div></body></html>